{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d03ff21e",
   "metadata": {},
   "source": [
    "# Weather data combine and average hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f25f7e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using Dates\n",
    "using Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8090ecf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/prabu/Desktop/Joppa/Raw_data/Weather_3/\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Local machine path to raw data\n",
    "path = \"/Users/prabu/Desktop/Joppa/Raw_data/Weather_3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c47c7463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{String}:\n",
       " \"2022\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_path = filter(isdir,readdir(path,join=true)) \n",
    "years = basename.(years_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8d2ac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "function ss(dirr, csvv, sensr)\n",
    "    df = CSV.read(dirr, DataFrame)\n",
    "    \n",
    "    try\n",
    "    \tdf.dateTime =  SubString.(string.(df.dateTime), 1, 19) \n",
    "    \tdf.dateTime = DateTime.(df.dateTime,\"yyyy-mm-dd HH:MM:SS\")  \n",
    "        #println(df)\n",
    "    \tdf.dateTime = map((x) -> round(x, Dates.Minute(10)), df.dateTime)  \n",
    "    \tgdf = groupby(df, :dateTime)  \n",
    "    \tcgdf = combine(gdf, valuecols(gdf) .=> mean)\n",
    "    \n",
    "    \tcolFullName = names(cgdf)\n",
    "    \tfor x in 2:length(colFullName)                                      # Starting from 2nd column and go through all the columns           \n",
    "            num_let = length(colFullName[x])                                # taking number of characters in one column name\n",
    "            colName = SubString.(string.(colFullName[x]), 1, num_let-5)     # removing last five characters of each column name (that is _mean)\n",
    "            rename!(cgdf,colFullName[x] => sensr*\"_\"*colName)               # adding sensor name to the column name\n",
    "    \tend\n",
    "    \treturn cgdf  \n",
    "    \t\n",
    "    catch e println(\"Error on \"*csvv) end\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd50b069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error on .DS_Store\n",
      "[\".DS_Store\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\"]\n"
     ]
    }
   ],
   "source": [
    "for y in years\n",
    "    months = readdir(path*\"/\"*y)\n",
    "    for m in months\n",
    "        try days = readdir(path*\"/\"*y*\"/\"*m)\n",
    "            println(days)\n",
    "        catch e println(\"error on \"*m) end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "900c4f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error on .DS_Store\n",
      "error on .DS_Store\n",
      "[\"00\", \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\"]\n",
      "error on 16\n",
      "[\"00\", \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\"]\n",
      "error on 17\n",
      "[\"00\", \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\"]\n",
      "error on 18\n",
      "[\"00\", \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\"]\n",
      "error on 19\n",
      "[\"00\", \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\"]\n",
      "error on 20\n",
      "[\"00\", \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\"]\n",
      "error on 21\n",
      "[\"00\", \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\"]\n",
      "error on 22\n",
      "[\"00\", \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\"]\n",
      "error on 23\n",
      "[\"00\", \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\"]\n",
      "error on 24\n",
      "[\"00\", \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\"]\n",
      "error on 25\n",
      "[\"00\", \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\"]\n",
      "error on 26\n",
      "[\"00\", \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\"]\n",
      "error on 27\n",
      "[\"00\", \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\"]\n",
      "error on 28\n",
      "[\"00\", \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\"]\n",
      "error on 29\n",
      "[\"00\", \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\"]\n",
      "error on 30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "k = 0\n",
    "for y in years\n",
    "    months = readdir(path*\"/\"*y)\n",
    "    for m in months\n",
    "        try days = readdir(path*\"/\"*y*\"/\"*m)\n",
    "            for d in days\n",
    "                try filess = readdir(path*\"/\"*y*\"/\"*m*\"/\"*d)\n",
    "                    println(filess)\n",
    "                    CSV_file = \"MINTS_\"*nodeId*\"_\"*sensor*\"_\"*y*\"_\"*m*\"_\"*d*\".csv\"\n",
    "                        \n",
    "                    if (CSV_file in filess)\n",
    "                        dir = path*\"/\"*y*\"/\"*m*\"/\"*d*\"/\"*CSV_file\n",
    "                        averaged_df = ss(dir, CSV_file, sensor)\n",
    "                        df2 = averaged_df\n",
    "                        k = k + 1\n",
    "                        if (k > 1) global new_df = outerjoin(new_df, df2, on = intersect(names(new_df), names(df2)))\n",
    "                        else new_df = averaged_df end\n",
    "                    else println(\"No data of \"*sensor) end\n",
    "                        \n",
    "                catch e println(\"error on \"*d) end\n",
    "            end\n",
    "        catch e println(\"error on \"*m) end\n",
    "    end\n",
    "end\n",
    "#=\n",
    "    global n = n + 1\n",
    "    if (n > 1) global final_df = outerjoin(final_df, new_df, on = :dateTime, makeunique=true) \n",
    "    else final_df = new_df end\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f225c01e",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: new_df not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: new_df not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ :0",
      " [2] eval",
      "   @ ./boot.jl:373 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc319f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
